{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXqwKcXH4n1yDXz4xSQrR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/111718105068/ranjith/blob/main/Machine_learning_with_python_Day2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Housing Prices with Regularized Regression"
      ],
      "metadata": {
        "id": "ODATQr_yWyHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Preparation\n"
      ],
      "metadata": {
        "id": "Gm9mEd-mvLHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MsmQlOn2u9X4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the housing price dataset\n",
        "df = pd.read_csv('housing_price_dataset.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the data\n",
        "df.head()\n",
        "\n",
        "# Check for missing values\n",
        "df.isnull().sum()\n",
        "\n",
        "# Handle missing values\n",
        "# ...\n",
        "\n",
        "# Identify and remove outliers\n",
        "# ...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PWJsmn2xOnq",
        "outputId": "e7e443c3-f4e8-4b66-c9dd-003c6e3b12f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "price               0\n",
              "area                0\n",
              "bedrooms            0\n",
              "bathrooms           0\n",
              "stories             0\n",
              "mainroad            0\n",
              "guestroom           0\n",
              "basement            0\n",
              "hotwaterheating     0\n",
              "airconditioning     0\n",
              "parking             0\n",
              "prefarea            0\n",
              "furnishingstatus    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('price', axis=1), df['price'], test_size=0.25)\n"
      ],
      "metadata": {
        "id": "W9LG6IaAxg3i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Implement Lasso Regression"
      ],
      "metadata": {
        "id": "Rz_1pzIjxmW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the features to use in the model\n",
        "features = ['area', 'bedrooms', 'bathrooms']\n",
        "\n",
        "# Define the independent and dependent variables\n",
        "X = X_train[features]\n",
        "y = y_train\n"
      ],
      "metadata": {
        "id": "wwaX7MNF12wj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Create a Lasso regression model\n",
        "lasso = Lasso()\n",
        "\n",
        "# Fit the model to the training data\n",
        "lasso.fit(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "B-wkLtF01_xi",
        "outputId": "22af3609-b5f1-4333-c492-5bb85bdced27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# c. Discuss the impact of L1 regularization on feature selection and coefficients."
      ],
      "metadata": {
        "id": "uFAqRsGt2XxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 regularization in Lasso regression penalizes the absolute values of the model coefficients. This can lead to feature selection, where some features are assigned zero coefficients and are effectively removed from the model. L1 regularization can also shrink the coefficients of non-zero features, which can help to reduce overfitting."
      ],
      "metadata": {
        "id": "tNMWqzD02bR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Evaluate the Lasso Regression"
      ],
      "metadata": {
        "id": "GOX8i69_2fwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = lasso.predict(X_test)\n",
        "\n",
        "# Calculate the evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('MAE:', mae)\n",
        "print('MSE:', mse)\n",
        "print('RMSE:', rmse)\n",
        "print('R2:', r2)\n"
      ],
      "metadata": {
        "id": "jRKtTcUxXCVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# b. Discuss how the Lasso model helps prevent overfitting and reduces the impact of irrelevant features"
      ],
      "metadata": {
        "id": "HkZvFU1c6DuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Lasso model helps prevent overfitting by penalizing the absolute values of the model coefficients. This can lead to feature selection, where some irrelevant features are assigned zero coefficients and are effectively removed from the model. Additionally, the Lasso model can shrink the coefficients of non-zero features, which can help to reduce the impact of irrelevant features on the model's predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "4ydYVCBb6MMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Implement Ridge Regression"
      ],
      "metadata": {
        "id": "6Ap7Pavb6PCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the features to use in the model\n",
        "features = ['area', 'bedrooms', 'bathrooms']\n",
        "\n",
        "# Define the independent and dependent variables\n",
        "X = X_train[features]\n",
        "y = y_train\n"
      ],
      "metadata": {
        "id": "n2foZ9aA2fdG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Create a Ridge regression model\n",
        "ridge = Ridge()\n",
        "\n",
        "# Fit the model to the training data\n",
        "ridge.fit(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "qwJc4tlM6h7J",
        "outputId": "d71d9ee9-a947-4a42-f783-a303d6ee4473"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# c. Explain how L2 regularization in Ridge regression differs from L1 regularization in Lasso."
      ],
      "metadata": {
        "id": "Sr5fven-XLcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 regularization in Ridge regression penalizes the squared values of the model coefficients. This can shrink the coefficients of all features, but it does not lead to feature selection like L1 regularization. L2 regularization can be helpful for handling multicollinearity among features."
      ],
      "metadata": {
        "id": "Fnwd8w8CXUBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Evaluate the Ridge Regression Model**"
      ],
      "metadata": {
        "id": "kuzZ-4ePXdyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "ridge_predictions = ridge.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, ridge_predictions)\n",
        "mse = mean_squared_error(y_test, ridge_predictions)\n",
        "rmse = np.sqrt(mse)\n"
      ],
      "metadata": {
        "id": "YDjmBrS4Ye3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **b. Discuss the benefits of Ridge regression in handling multicollinearity among features and its impact on the model's coefficients:**"
      ],
      "metadata": {
        "id": "0YP5fpf_YgF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge regression is effective in handling multicollinearity, which is when features are highly correlated. It does this by adding a penalty term to the sum of squared coefficients. The benefits are:\n",
        "\n",
        "Reduces multicollinearity: Ridge reduces the impact of multicollinearity by distributing the coefficients among correlated features, preventing one feature from dominating the others.\n",
        "\n",
        "Stabilizes coefficient estimates: Ridge stabilizes coefficient estimates by shrinking them, making the model less sensitive to changes in the data. This leads to more robust coefficients.\n",
        "\n",
        "No feature elimination: Ridge doesn't perform feature selection like Lasso, which can be beneficial when all features are important."
      ],
      "metadata": {
        "id": "Q3fjFeSMYvFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6: Model Comparison"
      ],
      "metadata": {
        "id": "eRKsEvJ3ZCSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "b. Discuss when it is preferable to use Lasso, Ridge, or plain linear regression:\n",
        "\n",
        "Use plain linear regression when you have no multicollinearity issues and believe that all features are relevant.\n",
        "Use Lasso when feature selection is crucial, and you want to eliminate irrelevant features.\n",
        "Use Ridge when you have multicollinearity and want a more stable model with all features retained."
      ],
      "metadata": {
        "id": "bIzGFjLLZKL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7: Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "xKNN1qrYZU7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Example of hyperparameter tuning for Ridge\n",
        "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "grid = GridSearchCV(Ridge(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "optimal_alpha = grid.best_params_['alpha']\n"
      ],
      "metadata": {
        "id": "NoOeqQuBZh0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diagnosing and Remedying Heteroscedasticity and Multicollinearity**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u8t3NGQ_vJ0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Initial Linear Regression Model"
      ],
      "metadata": {
        "id": "G27x-SqabEHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **a. Describe the dataset and the variables you're using for predicting employee performance:**\n",
        "\n",
        "Provide a brief overview of the dataset, including the variables used for predicting employee performance, such as experience, education level, and the number of projects completed."
      ],
      "metadata": {
        "id": "O8FnlHqbbKoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# X contains the independent variables, and y contains the target variable\n",
        "reg = LinearRegression()\n",
        "reg.fit(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "srQXaCcPbQ0v",
        "outputId": "0899448a-a68a-47dd-9f86-4cf7223eb274"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# c. Discuss why linear regression is a suitable choice for this prediction problem."
      ],
      "metadata": {
        "id": "ZrQ1qD3-s31B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression is a suitable choice for this prediction problem because the relationship between the predictor variables and the target variable is likely to be linear. This is because the predictor variables, such as experience, education level, and number of projects completed, are all thought to have a direct and proportional relationship with employee performance."
      ],
      "metadata": {
        "id": "BqOub3hfs9yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Identifying Heteroscedasticity"
      ],
      "metadata": {
        "id": "zPZOH4HFtAk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **a. Explain what heteroscedasticity is in the context of linear regression.**\n",
        "\n",
        "Heteroscedasticity is a violation of one of the assumptions of linear regression, which is that the variance of the residuals is constant across all values of the predictor variables. In other words, heteroscedasticity occurs when the magnitude of the residuals is not the same for all observations.\n",
        "\n",
        "# b. Provide methods for diagnosing heteroscedasticity in a regression model.\n",
        "\n",
        "There are a number of methods for diagnosing heteroscedasticity, including:\n",
        "\n",
        "Residual plots: A residual plot is a scatter plot of the residuals against the fitted values. If the variance of the residuals is constant, the residual plot will be evenly distributed around the zero line. If the variance of the residuals is not constant, the residual plot will show a pattern, such as a fan shape or a cone shape.\n",
        "Breusch-Pagan test: The Breusch-Pagan test is a statistical test for heteroscedasticity. The null hypothesis of the test is that there is no heteroscedasticity. The alternative hypothesis is that there is heteroscedasticity. If the p-value of the test is less than a significance level, such as 0.05, then the null hypothesis is rejected and we conclude that there is heteroscedasticity."
      ],
      "metadata": {
        "id": "22kKeRh7tbrB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zFQTNcQKs6C-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}